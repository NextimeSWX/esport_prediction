{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d55893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook d'Exploration des Donn√©es CS:GO\n",
    "# √âcole89 - 2025 - Projet Machine Learning\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from config.config import RAW_DATA_DIR, COLORS, PLOT_STYLE\n",
    "\n",
    "plt.style.use(PLOT_STYLE)\n",
    "sns.set_palette([COLORS['primary'], COLORS['secondary'], COLORS['accent']])\n",
    "\n",
    "print(\"=== EXPLORATION DES DONN√âES CS:GO ===\")\n",
    "print(\"Projet de Machine Learning - √âcole89 2025\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. CHARGEMENT DES DONN√âES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n1. üìÅ Chargement des donn√©es...\")\n",
    "\n",
    "# Charger les donn√©es brutes\n",
    "df = pd.read_csv(RAW_DATA_DIR / \"csgo_raw_data.csv\")\n",
    "\n",
    "print(f\"‚úÖ Dataset charg√©: {len(df)} joueurs, {len(df.columns)} variables\")\n",
    "print(f\"üìä P√©riode des donn√©es: Donn√©es simul√©es CS:GO\")\n",
    "\n",
    "# Aper√ßu des donn√©es\n",
    "print(f\"\\nüìã Aper√ßu des donn√©es:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\nüìä Informations g√©n√©rales:\")\n",
    "print(df.info())\n",
    "\n",
    "# ============================================================================\n",
    "# 2. ANALYSE DESCRIPTIVE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n2. üìà Analyse descriptive...\")\n",
    "\n",
    "# Statistiques de base\n",
    "print(f\"\\nüìä Statistiques descriptives:\")\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "print(df[numeric_cols].describe())\n",
    "\n",
    "# Distribution de la variable cible\n",
    "print(f\"\\nüéØ Distribution de la variable cible:\")\n",
    "target_dist = df['high_performer'].value_counts()\n",
    "print(target_dist)\n",
    "print(f\"Pourcentage de high performers: {df['high_performer'].mean():.1%}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. VISUALISATIONS EXPLORATOIRES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n3. üé® G√©n√©ration des visualisations...\")\n",
    "\n",
    "# Figure 1: Distribution de la variable cible\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Graphique en barres\n",
    "target_counts = df['high_performer'].value_counts()\n",
    "ax1.bar(['Low Performer', 'High Performer'], target_counts.values, \n",
    "        color=[COLORS['danger'], COLORS['success']], alpha=0.8)\n",
    "ax1.set_title('Distribution des Performances')\n",
    "ax1.set_ylabel('Nombre de joueurs')\n",
    "\n",
    "# Graphique en secteurs\n",
    "ax2.pie(target_counts.values, labels=['Low Performer', 'High Performer'], \n",
    "        colors=[COLORS['danger'], COLORS['success']], autopct='%1.1f%%')\n",
    "ax2.set_title('R√©partition des Performances')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Figure 2: Distributions des variables principales\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "key_variables = ['total_kills', 'total_deaths', 'total_time_played', \n",
    "                'total_damage_done', 'total_money_earned', 'total_mvps']\n",
    "\n",
    "for i, var in enumerate(key_variables):\n",
    "    if var in df.columns:\n",
    "        axes[i].hist(df[var], bins=30, alpha=0.7, color=COLORS['primary'])\n",
    "        axes[i].set_title(f'Distribution: {var}')\n",
    "        axes[i].set_xlabel(var)\n",
    "        axes[i].set_ylabel('Fr√©quence')\n",
    "\n",
    "plt.suptitle('Distributions des Variables Principales', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Figure 3: Comparaison par niveau de performance\n",
    "performance_vars = ['total_kills', 'total_deaths', 'kd_ratio', 'accuracy', 'win_rate']\n",
    "available_vars = [var for var in performance_vars if var in df.columns]\n",
    "\n",
    "if len(available_vars) >= 4:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, var in enumerate(available_vars[:4]):\n",
    "        df.boxplot(column=var, by='high_performer', ax=axes[i])\n",
    "        axes[i].set_title(f'{var} par Performance')\n",
    "        axes[i].set_xlabel('Niveau de Performance')\n",
    "        axes[i].set_ylabel(var)\n",
    "    \n",
    "    plt.suptitle('Comparaison par Niveau de Performance', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 4. ANALYSE DES CORR√âLATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n4. üîó Analyse des corr√©lations...\")\n",
    "\n",
    "# Matrice de corr√©lation\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "# Heatmap des corr√©lations\n",
    "plt.figure(figsize=(14, 12))\n",
    "mask = np.triu(correlation_matrix)  # Masquer la partie sup√©rieure\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', \n",
    "            center=0, fmt='.2f', square=True, cbar_kws={'label': 'Corr√©lation'})\n",
    "plt.title('Matrice de Corr√©lation des Variables', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top corr√©lations avec la variable cible\n",
    "if 'high_performer' in correlation_matrix.columns:\n",
    "    target_corr = correlation_matrix['high_performer'].abs().sort_values(ascending=False)\n",
    "    print(f\"\\nüéØ Top 10 corr√©lations avec high_performer:\")\n",
    "    for var, corr in target_corr.head(11).items():  # 11 car high_performer avec elle-m√™me = 1\n",
    "        if var != 'high_performer':\n",
    "            print(f\"  {var:<25}: {corr:.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. ANALYSE DES PATTERNS M√âTIER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n5. üéÆ Analyse des patterns m√©tier CS:GO...\")\n",
    "\n",
    "# Analyse des armes\n",
    "weapon_cols = [col for col in df.columns if 'total_kills_' in col and col != 'total_kills']\n",
    "\n",
    "if weapon_cols:\n",
    "    weapon_data = df[weapon_cols + ['high_performer']].copy()\n",
    "    \n",
    "    # Moyennes par niveau de performance\n",
    "    weapon_means = weapon_data.groupby('high_performer')[weapon_cols].mean()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    weapon_means.T.plot(kind='bar', ax=plt.gca())\n",
    "    plt.title('Kills par Arme selon le Niveau de Performance')\n",
    "    plt.xlabel('Type d\\'arme')\n",
    "    plt.ylabel('Nombre moyen de kills')\n",
    "    plt.legend(['Low Performer', 'High Performer'])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Analyse temporelle\n",
    "if 'total_time_played' in df.columns:\n",
    "    # Convertir en heures\n",
    "    df['hours_played'] = df['total_time_played'] / 3600\n",
    "    \n",
    "    # Distribution du temps de jeu\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "# Analyse temporelle\n",
    "if 'total_time_played' in df.columns:\n",
    "    # Convertir en heures\n",
    "    df['hours_played'] = df['total_time_played'] / 3600\n",
    "    \n",
    "    # Distribution du temps de jeu\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(df['hours_played'], bins=30, alpha=0.7, color=COLORS['primary'])\n",
    "    plt.title('Distribution du Temps de Jeu')\n",
    "    plt.xlabel('Heures jou√©es')\n",
    "    plt.ylabel('Nombre de joueurs')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    df.boxplot(column='hours_played', by='high_performer')\n",
    "    plt.title('Temps de Jeu par Performance')\n",
    "    plt.suptitle('')  # Supprimer le titre automatique\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Analyse KDA (Kill/Death/Assist)\n",
    "if all(col in df.columns for col in ['total_kills', 'total_deaths', 'total_assists']):\n",
    "    # Calcul KDA si pas d√©j√† fait\n",
    "    if 'kd_ratio' not in df.columns:\n",
    "        df['kd_ratio'] = df['total_kills'] / (df['total_deaths'] + 1)\n",
    "    \n",
    "    # Scatter plot KDA vs Performance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    low_perf = df[df['high_performer'] == 0]\n",
    "    high_perf = df[df['high_performer'] == 1]\n",
    "    \n",
    "    plt.scatter(low_perf['total_kills'], low_perf['total_deaths'], \n",
    "               alpha=0.6, c=COLORS['danger'], label='Low Performer', s=30)\n",
    "    plt.scatter(high_perf['total_kills'], high_perf['total_deaths'], \n",
    "               alpha=0.6, c=COLORS['success'], label='High Performer', s=30)\n",
    "    \n",
    "    plt.xlabel('Total Kills')\n",
    "    plt.ylabel('Total Deaths')\n",
    "    plt.title('Relation Kills vs Deaths par Performance')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 6. D√âTECTION D'ANOMALIES ET OUTLIERS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n6. üö® D√©tection d'anomalies...\")\n",
    "\n",
    "# Fonction pour d√©tecter les outliers avec IQR\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Analyser les outliers pour les variables principales\n",
    "outlier_vars = ['total_kills', 'total_deaths', 'total_damage_done', 'total_money_earned']\n",
    "available_outlier_vars = [var for var in outlier_vars if var in df.columns]\n",
    "\n",
    "outlier_summary = {}\n",
    "\n",
    "for var in available_outlier_vars:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df, var)\n",
    "    outlier_summary[var] = {\n",
    "        'count': len(outliers),\n",
    "        'percentage': len(outliers) / len(df) * 100,\n",
    "        'bounds': (lower, upper)\n",
    "    }\n",
    "    \n",
    "    print(f\"  {var}: {len(outliers)} outliers ({len(outliers)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Visualisation des outliers\n",
    "if available_outlier_vars:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, var in enumerate(available_outlier_vars[:4]):\n",
    "        df.boxplot(column=var, ax=axes[i])\n",
    "        axes[i].set_title(f'Outliers: {var}')\n",
    "        axes[i].set_ylabel(var)\n",
    "    \n",
    "    plt.suptitle('D√©tection d\\'Outliers', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 7. INSIGHTS ET RECOMMANDATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n7. üí° Insights et recommandations...\")\n",
    "\n",
    "# Calculer quelques statistiques int√©ressantes\n",
    "insights = []\n",
    "\n",
    "# 1. Performance moyenne par cat√©gorie\n",
    "if 'kd_ratio' in df.columns:\n",
    "    high_perf_kd = df[df['high_performer'] == 1]['kd_ratio'].mean()\n",
    "    low_perf_kd = df[df['high_performer'] == 0]['kd_ratio'].mean()\n",
    "    insights.append(f\"KD Ratio moyen: High Performers ({high_perf_kd:.2f}) vs Low Performers ({low_perf_kd:.2f})\")\n",
    "\n",
    "# 2. Temps de jeu\n",
    "if 'hours_played' in df.columns:\n",
    "    high_perf_hours = df[df['high_performer'] == 1]['hours_played'].mean()\n",
    "    low_perf_hours = df[df['high_performer'] == 0]['hours_played'].mean()\n",
    "    insights.append(f\"Temps moyen: High Performers ({high_perf_hours:.0f}h) vs Low Performers ({low_perf_hours:.0f}h)\")\n",
    "\n",
    "# 3. Corr√©lations fortes\n",
    "if 'high_performer' in correlation_matrix.columns:\n",
    "    strong_corr = correlation_matrix['high_performer'].abs()\n",
    "    strong_corr = strong_corr[strong_corr > 0.3]\n",
    "    if len(strong_corr) > 1:  # Exclure high_performer avec elle-m√™me\n",
    "        insights.append(f\"Variables fortement corr√©l√©es: {len(strong_corr)-1} features avec |r| > 0.3\")\n",
    "\n",
    "# 4. Distribution des outliers\n",
    "total_outliers = sum([info['count'] for info in outlier_summary.values()])\n",
    "insights.append(f\"Outliers d√©tect√©s: {total_outliers} au total ({total_outliers/len(df)*100:.1f}% du dataset)\")\n",
    "\n",
    "print(\"\\nüîç INSIGHTS PRINCIPAUX:\")\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"  {i}. {insight}\")\n",
    "\n",
    "print(\"\\nüìù RECOMMANDATIONS POUR LE PREPROCESSING:\")\n",
    "print(\"  ‚úÖ Variables cibles bien √©quilibr√©es\" if abs(df['high_performer'].mean() - 0.5) < 0.1 else \"  ‚ö†Ô∏è D√©s√©quilibre des classes √† surveiller\")\n",
    "print(\"  ‚úÖ Donn√©es coh√©rentes\" if total_outliers < len(df) * 0.1 else \"  ‚ö†Ô∏è Nombreux outliers - nettoyage n√©cessaire\")\n",
    "print(\"  ‚úÖ Corr√©lations exploitables trouv√©es\" if len(strong_corr) > 3 else \"  ‚ö†Ô∏è Peu de corr√©lations fortes - feature engineering n√©cessaire\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. PR√âPARATION POUR LA SUITE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n8. üéØ Pr√©paration pour les √©tapes suivantes...\")\n",
    "\n",
    "# Sauvegarde des insights pour les notebooks suivants\n",
    "exploration_summary = {\n",
    "    'dataset_size': len(df),\n",
    "    'n_features': len(df.columns),\n",
    "    'target_balance': df['high_performer'].mean(),\n",
    "    'outlier_percentage': total_outliers / len(df) * 100,\n",
    "    'strong_correlations': len(strong_corr) - 1 if 'strong_corr' in locals() else 0,\n",
    "    'recommendations': {\n",
    "        'scaling_needed': True,  # Diff√©rentes √©chelles observ√©es\n",
    "        'outlier_treatment': total_outliers > len(df) * 0.05,\n",
    "        'feature_engineering': True,  # Toujours b√©n√©fique\n",
    "        'class_balancing': abs(df['high_performer'].mean() - 0.5) > 0.15\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"üìä R√©sum√© de l'exploration:\")\n",
    "print(f\"  Dataset: {exploration_summary['dataset_size']} joueurs, {exploration_summary['n_features']} features\")\n",
    "print(f\"  √âquilibre: {exploration_summary['target_balance']:.1%} high performers\")\n",
    "print(f\"  Qualit√©: {exploration_summary['outlier_percentage']:.1f}% outliers\")\n",
    "\n",
    "print(f\"\\nüöÄ Prochaines √©tapes recommand√©es:\")\n",
    "print(f\"  1. Data Cleaning (outliers: {'OUI' if exploration_summary['recommendations']['outlier_treatment'] else 'OPTIONNEL'})\")\n",
    "print(f\"  2. Feature Engineering (recommand√©)\")\n",
    "print(f\"  3. Scaling/Normalisation (n√©cessaire)\")\n",
    "print(f\"  4. Mod√©lisation avec validation crois√©e\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPLORATION TERMIN√âE AVEC SUCC√àS!\")\n",
    "print(\"üìì Passez au notebook 02_data_cleaning.ipynb\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Optionnel: Sauvegarder le summary pour les autres notebooks\n",
    "import json\n",
    "summary_path = Path.cwd().parent / \"data\" / \"exploration_summary.json\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    # Convertir les numpy types en types Python standard\n",
    "    summary_clean = {}\n",
    "    for key, value in exploration_summary.items():\n",
    "        if isinstance(value, dict):\n",
    "            summary_clean[key] = {k: bool(v) if isinstance(v, (np.bool_, bool)) else float(v) if isinstance(v, (np.number, int, float)) else v for k, v in value.items()}\n",
    "        else:\n",
    "            summary_clean[key] = float(value) if isinstance(value, (np.number, int, float)) else value\n",
    "    \n",
    "    json.dump(summary_clean, f, indent=2)\n",
    "\n",
    "print(f\"üíæ R√©sum√© sauvegard√©: {summary_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
